* overview
- we use kubernetes api objects to describe cluster's desired state
- what applications to run
- what container image they use
- no of raplicas
- network and disk/cpu usage

- kubernetes performs variety of tasks automatically
- starting/restarting containers
- scaling no of replicas

- kubernetes master- three processes that run on a single node
- kube-apiserver
- kube-controller-manager
- kube-scheduler

- other/worker node - two processes on each node
- kubelet: communicates with the master
- kube-proxy: proxy network that reflects networking services on each node

* kubernetes-objects
- basic objects
- pod
- service
- volume
- namespace

- high level abstractions: controllers
- based on basic objects
- provides additional functionality

- controllers
- replicaset
- deployment
- statefulset
- daemonset
- job

* kubernetes control plane
- govern how kubernetes communicates with the cluster
- maintains record of all objects
- runs continuous loop to manage those objects state
- responses to change in the claster: work to make actual state to match desired state for all objects


*** kubernetes master
- maintains desired state of the cluster

*** kubernetes nodes
- machines (vm/physical server)
- run apps
- managed my master

* [[https://kubernetes.io/docs/concepts/overview/components][kubernetes components]]
** master components
*** kube-apiserver
- exposes the kubernetes api
- front-end for kubernetes control plane

*** etcd
- key-value store: storeage for all cluster data

*** kube-scheduler
- watches newly created pods
- assigns nodes to them

*** kube-controller-manager
- runs controller(control loop: watches the state of the cluster, works to move current state to desired state)
- each controller: separate process, single binary, runs as signle process
- node controller: notice and responds when nodes go down
- replication controller: maintains the correct number of pods
- endpoints controller: populates the endpoints objects(joins services and pods)
- service account and token controller: create accounts and api access tokens for new namespace

*** cloud controller manager
- runs controller that interacts with underlying cloud providers
- controllers:
- node controllers: checks the cloud provider to determine if a node has been deleted
- router controllers: sets up routes in underlying cloud infra
- service controller: create/update/delete cloud provider node balancer
- volume controller: attach/mount/interacts with cloud provider volumes

** node components
- runs on every nodes
- maintains running pods

*** kubelet
- makes sure that containers are running in a pod
- pods are running and healthy
- doesn't manage containers

*** kube-proxy
*** container runtime
* [[https://kubernetes.io/docs/concepts/overview/kubernetes-api/][kubernetes api]]
* [[https://kubernetes.io/docs/concepts/overview/working-with-objects/kubernetes-objects/][working with kubernetes objects]]
** overview
- persistent entities in the kubernetes system
- kubernetes uses these entities to represent state of the cluster
  - what apps are running, on which nodes
  - resources available to the apps
  - policies around how those apps behave(restart policies, upgrade, fault-tolerance)
- once objects are created, kubernetes works to ensure that objects remain exist

*** object spec and status
 - every object includes two nested object fields that govern the object's configuration: object spec and object status
 - object spec
   - one must provide
   - describes desired state for the object
 - object status
   - actual state of the object
   - supplied and updated by kubernetes
   - kubernetes control plane manages objects actual state to match desired state
** names
** namespaces
- kubernetes supports multiple vertical clusters backed by same physical server
- these virtual clusters are namespaces

*** when to use multiple namespaces
- many users spread across multiple teams/projects
- divide cluster resources between multiple users

*** viewing namespaces
#+BEGIN_SRC shebang
$ kubectl get namespaces
NAME          STATUS    AGE
default       Active    1d
kube-system   Active    1d
kube-public   Active    1d
#+END_SRC

- three initial namespaces
  - default: default namespaces
  - kube-system: namespace for objects created by kubernetes system
  - kube-public: readable by all users
  - 
** labels and selectors
*** labels
- key-value pairs that are attached to an object
- identify attributes of an object that are meaningful to users
- organize and select subset of objects
- labels can be attached on creation/modified later
- 

*** selectors
- many objects  have same lables
- user can identify a set of objects via label selector
- empty label selector selects every object
- null label selector selects no object
- two types of selectors: equality based, set based
  - equality based: filter by keys and values
#+BEGIN_SRC yaml
apiVersion: v1
kind: pod
metadata:
  name: cuda-test
spec:
  containers:
  - name: cuda-test
    image: "k8s.gcr.io/cuda-vector-add:v0.1"
    resources:
      limits:
        nvidia.com/gpu: 1
  nodeSelector:
    accelerator: nvidia-tesla-p100
#+END_SRC
  - set based: allows filtering keys according to a set of values
#+BEGIN_SRC
environment in (production, qa)
tier notin (frontend, backend)
partion
!partition
#+END_SRC

*** watch and list filtering
#+BEGIN_SRC shellbang
kubectl get pods -l environment=production,tier=frontend
kubectl get pods -l 'environment in (production), tier in(frontend)'
kubectl get pods -l 'environment in (production, qa)'
kubectl get pods -l 'environment,environment notin (frontend)'
#+END_SRC

#+BEGIN_SRC yaml
selector:
  matchLabels:
    component: redis
  matchExpressions:
    - {key: tier, operator: In, values: [cache]}
    - {key: environment, operator: NotIn, values: [dev]}
#+END_SRC
** annotations
- non-identifying metadata
- one can use either label or annotation
- labels are used to select and find collection of objects that satisfy certain conditions
- annotations are not used to identify and select objects
- build, release, image information like timestamp, git branch, pr number, hash

** field selector
- select kubernetes objects based on value of one or more resource fields
$ kubectl get pods --field-sellector status.phase=Running
* [[https://kubernetes.io/docs/concepts/overview/object-management-kubectl/overview/][kubernetes object management]]
* kubernetes architecture 
** nodes
- worker machines
- vm/physical machine
- managed by master
- runs containers
- includes
  - container runtime
  - kubelet
  - kubeproxy
  

*** node controller
- master component
- manages various aspects of nodes
- assigns CIDR block
- update list of nodes
- monitor nodes' health
- when node becomes unhealthy, it asks the cloud provider if it is still available, if not deletes it from list of nodes

** master-node communication
*** cluster to master
- communication path terminate at apiserver(other master components are not exposed)
- apiserver listens at HTTPS 443 port
- nodes contain public root certificate of the cluster
- when pods are created, 

*** master to cluster
**** apiserver to kubelet
used for:
- fetching logs for pods
- attaching to running pods
- providing kubelet's port-forwarding functionality
- 

**** apiserver to nodes/pods/services
- HTTP connection
- not authenticated/encrypted
- not confurrently safe
** cloud controller manager
- design based on plugin mechanism
- allows cloud providers integrate with kubernetes using plugins
- 

*** without cloud controller manager
#+DOWNLOADED: /tmp/screenshot.png @ 2018-11-30 12:53:16
[[file:kubernetes%20architecture/screenshot_2018-11-30_12-53-16.png]]

*** with cloud controller manager
  
#+DOWNLOADED: /tmp/screenshot.png @ 2018-11-30 12:47:37
[[file:kubernetes%20architecture/screenshot_2018-11-30_12-47-37.png]]



*** cloud controller manager runs:
- node controller
- router controller
- service controller
- persistent volume label controller
**** node controller
- initialize a node with cloud specific zone/region label
- initialize a node with cloud specifi detail, type and size
- obtain node's network adress and hotname
- check if node is deleted from cloud, if yes then delete the kubernetes node object
**** route  controllers
- configures routes so containers on different nodes in the cluster can communicate with each other
- only applicable for GCE clusters
**** service controller
- listens to service create, update, delete events
- configures cloud load balancers
- 

**** persistent volume labels controller
- applies labels on volumes when crated
- removes the need of users manually set the labels
- these labels are essential for scheduling pods, as they only work within the region/zone that they are in, so pods need to be in same region
- 

** kubelet
- node controller contains cloud dependent functionality of the kubelet
- before, kubelet was responsible for cloud-specific details(ip address, region/zone labels, instant type information)
- now, the initialization operations are done in ccm
- now, kubelet initialize a node without cloud specific information
- new nodes are unschedulable until ccm initializes the node with cloud specific informations
* [[https://kubernetes.io/docs/concepts/containers/][containers]]
* [[https://kubernetes.io/docs/concepts/workloads/pods/][pods]]
** overview
*** understanding pods
**** overview
- smallest deployable object
- basic building block
- smallest and simplest unit
- represents a running process
- pods encapsulate
  - application containers(or multiple containers)
  - storage
  - unique ip
  - options that govern how the containner(s) should run
- containers are tightly coupled and share resource
- single instance of an application
  - if scaled horizontally, multiple pods, one for each instance
  - replicated pods created and managed by controller

**** pods that run single containers
- most common use case
- pod as a wrapper around single container
- kubernetes manages pod rather than conntainers directly
 
**** pods that run multiple containers
- encapsulate an application that composed of multiple co-located containers that are tightly coupled and need to share resource
- form a single cohesive unit of service

**** how pods manage multiple containers
- multiple cooperating processes as containers form a cohesive unit of service
- containers are automatically co-located and co-scheduled on same node
- share resource, dependencies
- communicate with each other
- coordinate when and how to terminate
- advanced use case
- only use when containers are tightly coupled

**** shared networking
- each pod is assigned a unique ip address
- every container in a pod shares the network namespace including ip addresses and ports
- containers can communicate with each other using *localhost*

**** shared storage
- pod specify a set of shared storage volumes
- all containers can access the shared volumes
- allows persistent data in a pod
*** working with pods
- you'll rarely create individual pods directly
  - pods are designed as relatively short lived, disposable entities
  - when created, it is scheduled to run on a node
  - remains on that node until process terminates, then pod is deleted
  - do not self-heal
  - pods get deleted
    - if node fails
    - scheduling operations fails
    - lack of resource
    - node maintainance
- controller handles the work managing the disposable pod instances
- so, it is far more common to manage pods using a controller
*** pods and controllers
- create and manage multiple pods
- handles replication, rollout and self healing capabilities
- if node fails, controller might automatically replace the pod by scheduling an identical replacement on different node
- example of controllers that contain one or more pors
  - deployment
  - statefulset
  - daemonset
*** pod template
- pod specifications which are included in other objects such as replication controller, jobs, daemonset
- uses pod templates to make actual pods

#+BEGIN_SRC yaml
apiVersion: v1
kind: Pod
metadata:
  name: myapp-pod
  labels:
    app: myapp
spec:
  containers:
    - name: myapp-container
      image: busybox
      command: ['sh', '-c', 'echo hello kubernetes! && sleep 3600']
#+END_SRC

- after creation, pods can't be updated
- new template has no direct effect on pods already created
- but pods created by controllers can be updated directly
** pods
- pods are isolated by linux namespaces, cgroups
- within pod, individual containers are furher sub-isolationed
- containers within a pod share an ip addresses and port space
- find each other via localhost
- communicate with each other using standard inter process communications like semaphores or shared memory
- containers in different pods have different ip addresses
- can't communicate by IPC
- they communicate via pod ip address
- 

** termination of pods
- pods are gracefully terminated
- when users request deleteion of pod, system records the intended grace period and TERM signal is sent to main process of each container
- once grace period has expired, the KILL signal is send to those processes
- pods are then deleted from API server
